{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5285a4c0-006a-468a-8fa5-e915fff2a8e0",
   "metadata": {},
   "source": [
    "Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f99df54d-b5e6-414a-a72f-c7474052107b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "# from langchain.embeddings import OpenAIEmbeddings\n",
    "# from langchain.vectorstores.chroma import Chroma\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "# from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "import os\n",
    "import shutil\n",
    "# from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from pinecone import Pinecone\n",
    "from pinecone.exceptions import PineconeException\n",
    "import time\n",
    "from langchain_openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2df918-6b8c-4ff0-8ae2-8845f1cea8e6",
   "metadata": {},
   "source": [
    "Paths to information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76fef3b7-cdac-4d73-9d86-4e355f53f36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to input documents\n",
    "DATA_PATH1 = \"fallout_content/PDFs\"\n",
    "DATA_PATH2 = \"fallout_content/Nukapedia\"\n",
    "DATA_PATH3 = \"fallout_content/YouTube_oxhorn\"\n",
    "DATA_PATH4 = \"fallout_content/YouTube_spanish\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e251a9c1-4829-4344-928a-65193283b5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()\n",
    "# prompt, model, parser\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "model = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model=\"gpt-3.5-turbo\")\n",
    "parser = StrOutputParser()\n",
    "\n",
    "template = \"\"\"\n",
    "Answer the question based on the context below. If you can't \n",
    "answer the question, reply \"I don't know\".\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94de272-a1b5-44fc-8ebc-4a4a930a2a84",
   "metadata": {},
   "source": [
    "Splitting the information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35639873-68ad-4eac-97a1-a1f39703355e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load documents from directory\n",
    "def load_documents(path, extension):\n",
    "    loader = DirectoryLoader(path, glob=extension)\n",
    "    return loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9a38892-1170-40aa-92bc-30812ed282d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text(documents: list[Document]):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=300,\n",
    "        chunk_overlap=100,\n",
    "        length_function=len,\n",
    "        add_start_index=True,\n",
    "    )\n",
    "    chunks = text_splitter.split_documents(documents)\n",
    "    print(f\"Split {len(documents)} documents into {len(chunks)} chunks.\")\n",
    "\n",
    "    # document = chunks[10]\n",
    "    # print(document.page_content)\n",
    "    # print(document.metadata)\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d0b51e0-e536-41b1-b077-97f7a8282032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def vectors_pinecone(embeddings, chunks):\n",
    "#     index_name = \"fallout\"\n",
    "#     pinecone = PineconeVectorStore.from_documents(\n",
    "#     chunks, embeddings, index_name=index_name\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f48d2da9-8321-4e84-880e-9dcdb366428f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data():\n",
    "    documents = load_documents(DATA_PATH2, \"*.txt\")\n",
    "    documents += load_documents(DATA_PATH1, \"*.pdf\")\n",
    "    documents += load_documents(DATA_PATH3, \"*.txt\")\n",
    "    documents += load_documents(DATA_PATH4, \"*.txt\")\n",
    "    chunks = split_text(documents)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87a071c6-01f9-426e-bb7e-e22bce65f0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 462 documents into 71350 chunks.\n"
     ]
    }
   ],
   "source": [
    "chunks = generate_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fcc0b72-8ad5-4e39-81d2-2e55d5398753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully indexed documents in fallout2\n"
     ]
    }
   ],
   "source": [
    "from pinecone import Pinecone, PineconeException\n",
    "try:\n",
    "    pinecone = Pinecone(api_key=PINECONE_API_KEY, timeout=60)  # Adjust timeout as needed\n",
    "    index_name = \"fallout2\"  # Define your Pinecone index name\n",
    "    # Assuming PineconeVectorStore.from_documents is a valid method\n",
    "    index = PineconeVectorStore.from_documents(chunks, embeddings, index_name=index_name)\n",
    "    \n",
    "    print(f\"Successfully indexed documents in {index_name}\")\n",
    "except PineconeException as e:\n",
    "    print(f\"An error occurred with Pinecone: {e}\")\n",
    "    index = None  # Ensure index is None if there was an error\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")\n",
    "    index = None  # Ensure index is None if there was an error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0baac716-83e1-4cc4-8cbc-95266168487e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Harold is a tree-like being who has undergone a spectacular mutation and goes by many names such as The Lord, Him, The One Who Grows, Gives, and Guides, and The Talking Tree.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = (\n",
    "    {\"context\": index.as_retriever(), \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | parser\n",
    ")\n",
    "chain.invoke(\"Who is Harold?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "291f7f1a-140a-45e0-8034-ad6914b947ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To make Curie human, you need to continue to talk to Mother Curie III until you have the option to ask her “What makes you think you’re right?” Curie will then recall a dream about the Prophet of Atom. You can pretend to be the Prophet of Atom, and if you are less than critically irradiated, she will not believe you. To convince Curie that you are the Prophet of Atom, you need to be critically irradiated.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"How to make Curie human?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702b62e1-e293-43c9-9772-eec49c333055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter your question (or type 'exit' to quit):  who is Maximus?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximus is a rookie soldier who is a low-ranking member of the Brotherhood of Steel.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter your question (or type 'exit' to quit):  who is the brotherhood of steel?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Brotherhood of Steel is a quasi-religious technocratic military order founded by members of the United States Armed Forces and the government-sponsored scientific community.\n"
     ]
    }
   ],
   "source": [
    "# Function to invoke the chain with a given question\n",
    "def ask_question(question):\n",
    "    return chain.invoke(question)\n",
    "\n",
    "# Main loop\n",
    "while True:\n",
    "    # Get user input\n",
    "    user_question = input(\"Please enter your question (or type 'exit' to quit): \")\n",
    "    \n",
    "    # Check if the user wants to exit the loop\n",
    "    if user_question.lower() == 'exit':\n",
    "        print(\"Exiting the question loop. Goodbye!\")\n",
    "        break\n",
    "    \n",
    "    # Invoke the chain with the user's question and print the result\n",
    "    response = ask_question(user_question)\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6347854b-5cf7-4403-9d82-fc8e77eafa62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
